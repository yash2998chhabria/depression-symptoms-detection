{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traind = pd.read_csv('all_nobias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traind = traind.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traind['condition']=traind.astype({'condition': 'int64'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence      object\n",
       "condition    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traind.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5731, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>It’s evil.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Fine I'll buzz it short.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050</th>\n",
       "      <td>scared myself the past few nights with these t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4472</th>\n",
       "      <td>\"Brothers Raphael and Michael.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>I really feel alone.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>I turned it off and stared at a wall for awhile.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>Caiaphas didn’t say New Orleans like a local w...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>I wanted to look good.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Anyways, so they continued to delay - I waited...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>Everytime something good happens ten more shit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>And I can’t help it.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>I know that I want to die and would be happy i...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>It fucking floored me and it continues to floo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>Nemta watched him poke at the hologram.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>But, hopefully not till there old enough to ha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>Not an ideal solution, but you can only handle...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>I visited my so called friend from high school.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>I graduated this month but I didn't attend.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>Water is 3 to 4 ft.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>All the passion I previously had for my course...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  condition\n",
       "1558                                         It’s evil.        0.0\n",
       "150                            Fine I'll buzz it short.        0.0\n",
       "5050  scared myself the past few nights with these t...        1.0\n",
       "4472                     \"Brothers Raphael and Michael.        0.0\n",
       "1229                               I really feel alone.        1.0\n",
       "1359   I turned it off and stared at a wall for awhile.        1.0\n",
       "538   Caiaphas didn’t say New Orleans like a local w...        0.0\n",
       "2808                             I wanted to look good.        0.0\n",
       "326   Anyways, so they continued to delay - I waited...        1.0\n",
       "1773  Everytime something good happens ten more shit...        1.0\n",
       "2553                               And I can’t help it.        1.0\n",
       "1575  I know that I want to die and would be happy i...        1.0\n",
       "3508  It fucking floored me and it continues to floo...        0.0\n",
       "1093            Nemta watched him poke at the hologram.        0.0\n",
       "126   But, hopefully not till there old enough to ha...        0.0\n",
       "488   Not an ideal solution, but you can only handle...        0.0\n",
       "3849    I visited my so called friend from high school.        1.0\n",
       "3941        I graduated this month but I didn't attend.        1.0\n",
       "2496                                Water is 3 to 4 ft.        0.0\n",
       "4306  All the passion I previously had for my course...        1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traind.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence     1827\n",
       "condition    1827\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count= traind['condition']==1\n",
    "check=traind[count]\n",
    "check.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence     0\n",
       "condition    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traind[traind.isnull().any(axis=1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traind = traind.sample(5731)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>“It was your lunch break not your naptime.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>In middle school my first ever girlfriend brok...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>I didn't give her what she needed.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>So right now, I feel like a failure after a we...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>She lost two ships in the scrum due to her dis...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>“Alice Winters, my gratitude for your haste in...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>Know the feeling when you fucked up in your li...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>Or I'll spend 30 minutes browsing Steam store ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>It’s not just some fun.ive been going through ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>I feel like I'm being judged for crying wolf.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  condition\n",
       "908          “It was your lunch break not your naptime.        0.0\n",
       "248   In middle school my first ever girlfriend brok...        1.0\n",
       "3922                 I didn't give her what she needed.        1.0\n",
       "2581  So right now, I feel like a failure after a we...        1.0\n",
       "1592  She lost two ships in the scrum due to her dis...        0.0\n",
       "1373  “Alice Winters, my gratitude for your haste in...        0.0\n",
       "3682  Know the feeling when you fucked up in your li...        1.0\n",
       "2427  Or I'll spend 30 minutes browsing Steam store ...        1.0\n",
       "4314  It’s not just some fun.ive been going through ...        0.0\n",
       "3055      I feel like I'm being judged for crying wolf.        0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traind.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“It was your lunch break not your naptime.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In middle school my first ever girlfriend brok...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didn't give her what she needed.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So right now, I feel like a failure after a we...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She lost two ships in the scrum due to her dis...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“Alice Winters, my gratitude for your haste in...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Know the feeling when you fucked up in your li...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Or I'll spend 30 minutes browsing Steam store ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It’s not just some fun.ive been going through ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I feel like I'm being judged for crying wolf.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The tears were not going to stop until I let e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Each choice branched out to more and more points.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Now steel yourselves soldiers of the Imperium,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I either lose intrest or am so out of mind tha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Whatever, thanks for listening to me for the -...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Unfortunately, over the years, I think I've he...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I am Jepthath, your king.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The part with me headbutting a so called frien...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I think this is a question website.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\r\\n\\r\\n“We are looking for the one they cal...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I'm back to smoking and feel it is all down hi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>coming....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I feel like I should just end everything since...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I’m planning on adopting and older, big dog fo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I dont know if this is like universal with peo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>or 'Doom' is a big honour seemingly.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>He described a plant with fruit that has a tox...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i havent had a hug in months.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Because I really don’t know what to do.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I basically broke my own fucking heart by bein...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701</th>\n",
       "      <td>The carpets were purple, with a very deep pile.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>Why?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>I don't know why I am holding on to life.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>Thinking of ways to get out of this shit-hole ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>Oppal spun to embrace Squishy, just as he drop...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>Today I tried talking to my mom and she didn’t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>It seemed like everyone was by each other’s side.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>\\-perhaps her body was in a state of decomposi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709</th>\n",
       "      <td>This person I do not like.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>Hello everybody\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nI'm new...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5711</th>\n",
       "      <td>Both me and my boyfriend suffer mental illnesses.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>I am genuinely considering moving into an isol...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713</th>\n",
       "      <td>-Fourth and to me, one of the most concerning ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>The last time I talked to her, she called me i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5715</th>\n",
       "      <td>My relationship with him became worse since.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>*\\r\\n\\r\\nMy next steps came with some more con...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>I don't know.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>When I have all this friendship willing to giv...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>it’s just so easy to not care.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>I decided to walk to the store today to make m...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>We used to text for hours and I even told you ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>No one sees my strugle really, mostly because ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>He than answer with \"We Never Went Through Any...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Now I have a home with a very expensive lien o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Four Years Ago:\\r\\n\\r\\nI'm waking up in a wate...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Mike turns around, ready to make  a run for  i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>I was just looking at this picture of myself f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>**\\[2lt.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5729</th>\n",
       "      <td>I went from being the one making the most mone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>44 years old and alone.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5731 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  condition\n",
       "0            “It was your lunch break not your naptime.        0.0\n",
       "1     In middle school my first ever girlfriend brok...        1.0\n",
       "2                    I didn't give her what she needed.        1.0\n",
       "3     So right now, I feel like a failure after a we...        1.0\n",
       "4     She lost two ships in the scrum due to her dis...        0.0\n",
       "5     “Alice Winters, my gratitude for your haste in...        0.0\n",
       "6     Know the feeling when you fucked up in your li...        1.0\n",
       "7     Or I'll spend 30 minutes browsing Steam store ...        1.0\n",
       "8     It’s not just some fun.ive been going through ...        0.0\n",
       "9         I feel like I'm being judged for crying wolf.        0.0\n",
       "10    The tears were not going to stop until I let e...        1.0\n",
       "11    Each choice branched out to more and more points.        0.0\n",
       "12    Now steel yourselves soldiers of the Imperium,...        0.0\n",
       "13    I either lose intrest or am so out of mind tha...        1.0\n",
       "14    Whatever, thanks for listening to me for the -...        1.0\n",
       "15    Unfortunately, over the years, I think I've he...        0.0\n",
       "16                            I am Jepthath, your king.        0.0\n",
       "17    The part with me headbutting a so called frien...        1.0\n",
       "18                  I think this is a question website.        0.0\n",
       "19      \\r\\n\\r\\n“We are looking for the one they cal...        0.0\n",
       "20    I'm back to smoking and feel it is all down hi...        1.0\n",
       "21                                           coming....        0.0\n",
       "22    I feel like I should just end everything since...        1.0\n",
       "23    I’m planning on adopting and older, big dog fo...        0.0\n",
       "24    I dont know if this is like universal with peo...        1.0\n",
       "25                 or 'Doom' is a big honour seemingly.        0.0\n",
       "26    He described a plant with fruit that has a tox...        0.0\n",
       "27                        i havent had a hug in months.        0.0\n",
       "28              Because I really don’t know what to do.        1.0\n",
       "29    I basically broke my own fucking heart by bein...        1.0\n",
       "...                                                 ...        ...\n",
       "5701    The carpets were purple, with a very deep pile.        0.0\n",
       "5702                                               Why?        0.0\n",
       "5703          I don't know why I am holding on to life.        1.0\n",
       "5704  Thinking of ways to get out of this shit-hole ...        1.0\n",
       "5705  Oppal spun to embrace Squishy, just as he drop...        0.0\n",
       "5706  Today I tried talking to my mom and she didn’t...        1.0\n",
       "5707  It seemed like everyone was by each other’s side.        0.0\n",
       "5708  \\-perhaps her body was in a state of decomposi...        0.0\n",
       "5709                         This person I do not like.        0.0\n",
       "5710  Hello everybody\\r\\n\\r\\n&#x200B;\\r\\n\\r\\nI'm new...        0.0\n",
       "5711  Both me and my boyfriend suffer mental illnesses.        1.0\n",
       "5712  I am genuinely considering moving into an isol...        1.0\n",
       "5713  -Fourth and to me, one of the most concerning ...        0.0\n",
       "5714  The last time I talked to her, she called me i...        0.0\n",
       "5715       My relationship with him became worse since.        0.0\n",
       "5716  *\\r\\n\\r\\nMy next steps came with some more con...        0.0\n",
       "5717                                      I don't know.        0.0\n",
       "5718  When I have all this friendship willing to giv...        0.0\n",
       "5719                     it’s just so easy to not care.        0.0\n",
       "5720  I decided to walk to the store today to make m...        0.0\n",
       "5721  We used to text for hours and I even told you ...        1.0\n",
       "5722  No one sees my strugle really, mostly because ...        0.0\n",
       "5723  He than answer with \"We Never Went Through Any...        1.0\n",
       "5724  Now I have a home with a very expensive lien o...        0.0\n",
       "5725  Four Years Ago:\\r\\n\\r\\nI'm waking up in a wate...        0.0\n",
       "5726  Mike turns around, ready to make  a run for  i...        0.0\n",
       "5727  I was just looking at this picture of myself f...        1.0\n",
       "5728                                           **\\[2lt.        0.0\n",
       "5729  I went from being the one making the most mone...        1.0\n",
       "5730                            44 years old and alone.        1.0\n",
       "\n",
       "[5731 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traind.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5731, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpedia_df = traind.astype({'condition': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence     object\n",
       "condition     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbpedia_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dbpedia_df['sentence']\n",
    "Y = dbpedia_df['condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908            “It was your lunch break not your naptime.\n",
       "248     In middle school my first ever girlfriend brok...\n",
       "3922                   I didn't give her what she needed.\n",
       "2581    So right now, I feel like a failure after a we...\n",
       "1592    She lost two ships in the scrum due to her dis...\n",
       "1373    “Alice Winters, my gratitude for your haste in...\n",
       "3682    Know the feeling when you fucked up in your li...\n",
       "2427    Or I'll spend 30 minutes browsing Steam store ...\n",
       "4314    It’s not just some fun.ive been going through ...\n",
       "3055        I feel like I'm being judged for crying wolf.\n",
       "115     The tears were not going to stop until I let e...\n",
       "932     Each choice branched out to more and more points.\n",
       "3432    Now steel yourselves soldiers of the Imperium,...\n",
       "3801    I either lose intrest or am so out of mind tha...\n",
       "1438    Whatever, thanks for listening to me for the -...\n",
       "3350    Unfortunately, over the years, I think I've he...\n",
       "581                             I am Jepthath, your king.\n",
       "3167    The part with me headbutting a so called frien...\n",
       "4036                  I think this is a question website.\n",
       "1186      \\r\\n\\r\\n“We are looking for the one they cal...\n",
       "5155    I'm back to smoking and feel it is all down hi...\n",
       "863                                            coming....\n",
       "4579    I feel like I should just end everything since...\n",
       "2472    I’m planning on adopting and older, big dog fo...\n",
       "4665    I dont know if this is like universal with peo...\n",
       "4648                 or 'Doom' is a big honour seemingly.\n",
       "335     He described a plant with fruit that has a tox...\n",
       "1848                        i havent had a hug in months.\n",
       "2923              Because I really don’t know what to do.\n",
       "3522    I basically broke my own fucking heart by bein...\n",
       "                              ...                        \n",
       "5379      The carpets were purple, with a very deep pile.\n",
       "5280                                                 Why?\n",
       "806             I don't know why I am holding on to life.\n",
       "4525    Thinking of ways to get out of this shit-hole ...\n",
       "1443    Oppal spun to embrace Squishy, just as he drop...\n",
       "1223    Today I tried talking to my mom and she didn’t...\n",
       "1197    It seemed like everyone was by each other’s side.\n",
       "3349    \\-perhaps her body was in a state of decomposi...\n",
       "2207                           This person I do not like.\n",
       "583     Hello everybody\\r\\n\\r\\n&#x200B;\\r\\n\\r\\nI'm new...\n",
       "1669    Both me and my boyfriend suffer mental illnesses.\n",
       "5374    I am genuinely considering moving into an isol...\n",
       "1946    -Fourth and to me, one of the most concerning ...\n",
       "4080    The last time I talked to her, she called me i...\n",
       "800          My relationship with him became worse since.\n",
       "77      *\\r\\n\\r\\nMy next steps came with some more con...\n",
       "4678                                        I don't know.\n",
       "2713    When I have all this friendship willing to giv...\n",
       "733                        it’s just so easy to not care.\n",
       "2247    I decided to walk to the store today to make m...\n",
       "3545    We used to text for hours and I even told you ...\n",
       "979     No one sees my strugle really, mostly because ...\n",
       "3089    He than answer with \"We Never Went Through Any...\n",
       "3783    Now I have a home with a very expensive lien o...\n",
       "3478    Four Years Ago:\\r\\n\\r\\nI'm waking up in a wate...\n",
       "836     Mike turns around, ready to make  a run for  i...\n",
       "716     I was just looking at this picture of myself f...\n",
       "5024                                             **\\[2lt.\n",
       "393     I went from being the one making the most mone...\n",
       "2766                              44 years old and alone.\n",
       "Name: sentence, Length: 5731, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5731, 54957)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=0, max_df=80, ngram_range=(1, 2))\n",
    "\n",
    "feature_vector = count_vectorizer.fit_transform(X)\n",
    "\n",
    "feature_vector.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5731, 54957)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "feature_vector = tfidf_transformer.fit_transform(feature_vector)\n",
    "\n",
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_classification(y_test, y_pred):\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(\"Length of testing data: \", len(y_test))\n",
    "    print(\"accuracy_count : \" , num_acc)\n",
    "    print(\"accuracy_score : \" , acc)\n",
    "    print(\"precision_score : \" , prec)\n",
    "    print(\"recall_score : \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense = feature_vector.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5731, 54957)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1938    1\n",
       "2834    0\n",
       "1856    1\n",
       "3830    0\n",
       "4372    0\n",
       "1286    0\n",
       "1963    0\n",
       "1732    0\n",
       "3051    0\n",
       "1934    0\n",
       "2781    0\n",
       "2034    1\n",
       "1311    1\n",
       "4254    0\n",
       "3641    0\n",
       "758     0\n",
       "1195    0\n",
       "2368    1\n",
       "4931    0\n",
       "5432    1\n",
       "1692    0\n",
       "3865    1\n",
       "3414    0\n",
       "4448    0\n",
       "5245    0\n",
       "2704    1\n",
       "1058    0\n",
       "2075    0\n",
       "3324    0\n",
       "1155    0\n",
       "       ..\n",
       "2274    0\n",
       "1369    0\n",
       "1326    0\n",
       "2295    0\n",
       "3202    0\n",
       "4819    0\n",
       "2132    0\n",
       "2412    1\n",
       "1367    0\n",
       "1188    0\n",
       "2151    1\n",
       "3900    0\n",
       "1926    1\n",
       "5380    0\n",
       "2013    1\n",
       "4204    1\n",
       "5517    0\n",
       "5068    0\n",
       "1961    1\n",
       "910     1\n",
       "2843    0\n",
       "938     0\n",
       "1890    0\n",
       "2267    0\n",
       "1115    0\n",
       "210     0\n",
       "5267    0\n",
       "5727    0\n",
       "155     1\n",
       "2630    0\n",
       "Name: condition, Length: 1147, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of testing data:  1147\n",
      "accuracy_count :  759\n",
      "accuracy_score :  0.6617262423714037\n",
      "precision_score :  0.6742549108372695\n",
      "recall_score :  0.6617262423714037\n"
     ]
    }
   ],
   "source": [
    "summarize_classification(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4584, 54957), (4584,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,  y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_ = torch.from_numpy(x_train).float()\n",
    "Xtest_ = torch.from_numpy(x_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4584, 54957])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_ = torch.from_numpy(y_train.values).view(1,-1)[0]\n",
    "Ytest_ = torch.from_numpy(y_test.values).view(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4584])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 54957\n",
    "output_size = 2\n",
    "hidden_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) \n",
    "        #self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        #x = F.sigmoid(self.fc3(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 100 (6%) train loss - 0.58 test loss - 0.62 accuracy - 0.6765\n",
      "epoch - 200 (13%) train loss - 0.26 test loss - 0.55 accuracy - 0.7079\n",
      "epoch - 300 (20%) train loss - 0.08 test loss - 0.52 accuracy - 0.7323\n",
      "epoch - 400 (26%) train loss - 0.04 test loss - 0.53 accuracy - 0.7306\n",
      "epoch - 500 (33%) train loss - 0.02 test loss - 0.56 accuracy - 0.7306\n",
      "epoch - 600 (40%) train loss - 0.02 test loss - 0.58 accuracy - 0.7297\n",
      "epoch - 700 (46%) train loss - 0.01 test loss - 0.61 accuracy - 0.7280\n",
      "epoch - 800 (53%) train loss - 0.01 test loss - 0.63 accuracy - 0.7289\n",
      "epoch - 900 (60%) train loss - 0.01 test loss - 0.65 accuracy - 0.7271\n",
      "epoch - 1000 (66%) train loss - 0.01 test loss - 0.67 accuracy - 0.7289\n"
     ]
    }
   ],
   "source": [
    "epoch_data = []\n",
    "epochs = 1001\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    Ypred = model(Xtrain_)\n",
    "\n",
    "    loss = loss_fn(Ypred , Ytrain_)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "        \n",
    "    Ypred_test = model(Xtest_)\n",
    "    loss_test = loss_fn(Ypred_test, Ytest_)\n",
    "    \n",
    "    _,pred = Ypred_test.data.max(1)\n",
    "    \n",
    "    accuracy = pred.eq(Ytest_.data).sum().item() / y_test.values.size\n",
    "    epoch_data.append([epoch, loss.data.item(), loss_test.data.item(), accuracy])\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print ('epoch - %d (%d%%) train loss - %.2f test loss - %.2f accuracy - %.4f'\\\n",
    "               % (epoch, epoch/150 * 10 , loss.data.item(), loss_test.data.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epochs_data = pd.DataFrame(epoch_data, \n",
    "                              columns=[\"epoch\", \"train_loss\", \"test_loss\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:3604: MatplotlibDeprecationWarning: \n",
      "The `ymin` argument was deprecated in Matplotlib 3.0 and will be removed in 3.2. Use `bottom` instead.\n",
      "  alternative='`bottom`', obj_type='argument')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "df_epochs_data[[\"train_loss\", \"test_loss\"]].plot(ax=ax1)\n",
    "df_epochs_data[[\"accuracy\"]].plot(ax=ax2)\n",
    "plt.ylim(ymin=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     i am very happy.\n",
      "1                         i feel good.\n",
      "2         this is working really well.\n",
      "3                       i am very sad.\n",
      "4    tera internet bohot slow hai bhai\n",
      "dtype: object\n",
      "null - 0\n",
      "null - 0\n",
      "null - 0\n",
      "symptom -  1\n",
      "null - 0\n"
     ]
    }
   ],
   "source": [
    "sent_tokens = sent_tokenize(\"i am very happy. i feel good. this is working really well. i am very sad. tera internet bohot slow hai bhai\")\n",
    "sent_tokens = pd.Series(sent_tokens)\n",
    "print(sent_tokens)\n",
    "sent_tokens = count_vectorizer.transform(sent_tokens).toarray()\n",
    "for sent in sent_tokens:\n",
    "    sample = np.array(sent)\n",
    "    sample_tensor = torch.from_numpy(sent).float()\n",
    "    out = model(sample_tensor)\n",
    "    _, predicted = torch.max(out.data, -1)\n",
    "    if predicted.item() == 0: \n",
    "        print(\"null -\", predicted.item())\n",
    "    elif predicted.item() == 1:\n",
    "        print(\"symptom - \", predicted.item())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = [\"im not happy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = count_vectorizer.transform(check).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 38953)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "check.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = np.array(check,dtype='int64')\n",
    "sample.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = torch.from_numpy(sample).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6861, -0.2773, -2.8661]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(sample_tensor)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(out.data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inconclusive -  1\n"
     ]
    }
   ],
   "source": [
    "if predicted.item() == 0: \n",
    "    print(\"null -\", predicted.item())\n",
    "elif predicted.item() == 1:\n",
    "    print(\"inconclusive - \", predicted.item())\n",
    "elif predicted.item() == 2:\n",
    "    print(\"conclusive - \", predicted.item())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1092, -0.1107, -0.1141,  ...,  0.0853,  0.0799,  0.0807],\n",
       "         [ 0.1224,  0.1236,  0.1291,  ..., -0.0602, -0.0601, -0.0607],\n",
       "         [ 0.0953,  0.0976,  0.1016,  ...,  0.0491,  0.0454,  0.0457],\n",
       "         ...,\n",
       "         [-0.1211, -0.1287, -0.1220,  ...,  0.0791,  0.0777,  0.0851],\n",
       "         [-0.0780, -0.0739, -0.0733,  ..., -0.1023, -0.1083, -0.1054],\n",
       "         [-0.0795, -0.0803, -0.0800,  ..., -0.0930, -0.1003, -0.0951]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0230, -0.1089,  0.0424, -0.0664, -0.0625, -0.0061, -0.1146, -0.0217,\n",
       "         -0.0301,  0.0157, -0.3092, -0.2701], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.6369,  0.9034,  0.8641,  0.6660, -1.0326,  0.2876,  0.8278,  0.7811,\n",
       "           0.7093,  0.3668, -0.9352, -0.5569],\n",
       "         [-0.3056,  0.4936,  0.9233, -0.3078, -0.5825, -0.8140,  0.9646, -0.5591,\n",
       "          -0.6588, -0.6178, -0.8532, -0.6452],\n",
       "         [-0.6466,  0.5541, -0.0889, -0.4142, -0.4628, -0.3598,  0.7904, -0.4038,\n",
       "          -0.4915, -0.4356,  0.4626,  0.4371],\n",
       "         [ 0.7127, -0.8724, -0.2912,  0.4483,  0.7646,  0.4540, -0.6805,  0.3221,\n",
       "           0.6579,  0.7019,  0.3440,  0.7300],\n",
       "         [ 0.6207,  0.7486,  0.7479,  0.1094, -0.8747,  0.4216,  0.8065,  0.6330,\n",
       "           0.2809,  0.6870, -0.7868, -0.9065],\n",
       "         [ 0.4687, -0.6215, -0.9008,  0.4295,  0.4031,  0.4298, -0.6050,  0.5571,\n",
       "           0.6334,  0.3994,  0.7765,  0.6529],\n",
       "         [-0.8841,  0.4835,  0.1624, -0.5323, -0.0670, -0.6941,  0.5581, -0.5589,\n",
       "          -0.7665, -0.6442,  1.0577,  0.7806],\n",
       "         [-0.6494, -0.9586, -1.0013, -0.5103,  0.7569, -0.7328, -0.7946, -0.5786,\n",
       "          -0.4635, -0.4471,  0.9834,  0.9130],\n",
       "         [ 0.5317, -0.5289, -0.5908,  0.8215,  0.5679,  0.7353, -0.8113,  0.5522,\n",
       "           0.5653,  0.4311, -0.6080, -0.6042],\n",
       "         [-0.5643,  0.7156,  0.7026, -0.5123, -0.7541, -0.4203,  0.4489, -0.7146,\n",
       "          -0.5612, -0.7199, -0.9543, -0.6852],\n",
       "         [ 0.7520, -0.4268,  0.3766,  0.7460, -0.5229,  0.7617, -0.7233,  0.2815,\n",
       "           0.5698,  0.5410, -0.6213, -0.8361],\n",
       "         [-0.8372,  0.3175,  0.1126, -0.8236,  0.3882, -0.5210,  0.3890, -0.7453,\n",
       "          -0.6360, -0.7960,  0.7238,  0.7520]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.2077, -0.0158,  0.6146, -0.5051,  0.0141, -0.0115,  0.6306,  0.2559,\n",
       "         -0.2736,  0.3606, -0.2496,  0.4702], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.4714, -0.2359, -0.3868,  0.6153,  0.4944,  0.6366, -0.5384, -0.5847,\n",
       "           0.4600, -0.6327,  0.6159, -0.7920],\n",
       "         [-0.7617, -0.3491,  0.4673,  0.1905, -0.8468,  0.4458,  0.6600,  0.7437,\n",
       "          -0.3282, -0.4007, -0.7742,  0.7214],\n",
       "         [ 0.6399,  0.9311,  0.8404, -0.7974,  0.7527, -1.0390,  0.5788, -0.7717,\n",
       "          -0.8314,  0.6964, -0.6037,  0.4293]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.1769,  0.0618, -0.2485], requires_grad=True)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/depred1final-38953-12.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=50688, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (fc3): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (fc4): Linear(in_features=10, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('./models/depsha15.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = 0\n",
    "ones = 0\n",
    "twos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           I want to tell them how I'm not faking it.\n",
      "1    I want to tell them how I'm really dying insid...\n",
      "2    Yeah, I know you've been freinds with him/her ...\n",
      "3    Someone new joins the group, and the blame goe...\n",
      "4    Ive known them for years, they can't be faking...\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 38953], m2: [50688 x 10] at C:\\w\\1\\s\\tmp_conda_3.7_021303\\conda\\conda-bld\\pytorch_1565316900252\\work\\aten\\src\\TH/generic/THTensorMath.cpp:752",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-4b21bd1f4092>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msample_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-0d3774b3915e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#x = F.sigmoid(self.fc3(x))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 38953], m2: [50688 x 10] at C:\\w\\1\\s\\tmp_conda_3.7_021303\\conda\\conda-bld\\pytorch_1565316900252\\work\\aten\\src\\TH/generic/THTensorMath.cpp:752"
     ]
    }
   ],
   "source": [
    "sent_tokens = sent_tokenize(\"I want to tell them how I'm not faking it. I want to tell them how I'm really dying inside, how I'm not doing it for attention, but all I get are shrugs and complaining and vague explanations over and over again, about how I dont know how he/she has it. Yeah, I know you've been freinds with him/her for more than 10 Blessed years, but that doesn't give you any right to judge or invalidate my feelings anymore than I already am. Someone new joins the group, and the blame goes on them. Ive known them for years, they can't be faking their mental illness.\")\n",
    "sent_tokens = pd.Series(sent_tokens)\n",
    "print(sent_tokens)\n",
    "sent_tokens = count_vectorizer.transform(sent_tokens).toarray()\n",
    "for sent in sent_tokens:\n",
    "    sample = np.array(sent)\n",
    "    sample_tensor = torch.from_numpy(sent).float()\n",
    "    out = model(sample_tensor)\n",
    "    _, predicted = torch.max(out.data, -1)\n",
    "    if predicted.item() == 0: \n",
    "        print(\"null -\", predicted.item())\n",
    "        zeros+=1\n",
    "    elif predicted.item() == 1:\n",
    "        print(\"inconclusive - \", predicted.item())\n",
    "        ones+=1\n",
    "    elif predicted.item() == 2:\n",
    "        print(\"conclusive - \", predicted.item()) \n",
    "        twos+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Lately I’ve met new people but I’m still alone.\n",
      "1    I fell in love too and I thought she liked me ...\n",
      "2    At the end of the day I’m alone and it’s the s...\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 38953], m2: [50688 x 10] at C:\\w\\1\\s\\tmp_conda_3.7_021303\\conda\\conda-bld\\pytorch_1565316900252\\work\\aten\\src\\TH/generic/THTensorMath.cpp:752",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-3913eb795fd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msample_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-0d3774b3915e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#x = F.sigmoid(self.fc3(x))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 38953], m2: [50688 x 10] at C:\\w\\1\\s\\tmp_conda_3.7_021303\\conda\\conda-bld\\pytorch_1565316900252\\work\\aten\\src\\TH/generic/THTensorMath.cpp:752"
     ]
    }
   ],
   "source": [
    "sent_tokens = sent_tokenize(\"Lately I’ve met new people but I’m still alone. I fell in love too and I thought she liked me too but there’s days where she’s friendly and talkative and other days where I don’t exist to her. At the end of the day I’m alone and it’s the same thing every single day\") \n",
    "sent_tokens = pd.Series(sent_tokens)\n",
    "print(sent_tokens)\n",
    "sent_tokens = count_vectorizer.transform(sent_tokens).toarray()\n",
    "for sent in sent_tokens:\n",
    "    sample = np.array(sent)\n",
    "    sample_tensor = torch.from_numpy(sent).float()\n",
    "    out = model(sample_tensor)\n",
    "    _, predicted = torch.max(out.data, -1)\n",
    "    if predicted.item() == 0: \n",
    "        print(\"null -\", predicted.item())\n",
    "        zeros+=1\n",
    "    elif predicted.item() == 1:\n",
    "        print(\"inconclusive - \", predicted.item())\n",
    "        ones+=1\n",
    "    elif predicted.item() == 2:\n",
    "        print(\"conclusive - \", predicted.item()) \n",
    "        twos+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
